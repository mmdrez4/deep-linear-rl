{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Restart the session after running this cell (Run it once!)\n",
        "!git clone https://github.com/sparisi/gym_gridworlds\n",
        "!pip install -e ./gym_gridworlds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlY9Ig2pE5qj",
        "outputId": "cb1f0754-5701-45cf-8759-dad3682dcab4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gym_gridworlds'...\n",
            "remote: Enumerating objects: 140, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 140 (delta 36), reused 51 (delta 24), pack-reused 69 (from 1)\u001b[K\n",
            "Receiving objects: 100% (140/140), 74.35 KiB | 624.00 KiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n",
            "Obtaining file:///content/gym_gridworlds\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gymnasium (from Gym-Gridworlds==1.0)\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from Gym-Gridworlds==1.0) (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->Gym-Gridworlds==1.0) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->Gym-Gridworlds==1.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->Gym-Gridworlds==1.0) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium->Gym-Gridworlds==1.0)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, Gym-Gridworlds\n",
            "  Running setup.py develop for Gym-Gridworlds\n",
            "Successfully installed Gym-Gridworlds-1.0 farama-notifications-0.0.4 gymnasium-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Register Envoronments in Gym"
      ],
      "metadata": {
        "id": "W3Gq3o_bGy10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gymnasium.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Straight-20-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=200,\n",
        "    kwargs={\n",
        "        \"grid\": \"20_straight\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Empty-2x2-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:GridworldRandomStart\",\n",
        "    max_episode_steps=10,\n",
        "    kwargs={\n",
        "        \"grid\": \"2x2_empty\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Empty-3x3-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:GridworldRandomStart\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"3x3_empty\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Empty-Loop-3x3-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"3x3_empty_loop\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Empty-10x10-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=100,\n",
        "    kwargs={\n",
        "        \"grid\": \"10x10_empty\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Empty-Distract-6x6-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"6x6_distract\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Penalty-3x3-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"3x3_penalty\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Quicksand-4x4-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"4x4_quicksand\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Quicksand-Distract-4x4-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"4x4_quicksand_distract\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/TwoRoom-Quicksand-3x5-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"3x5_two_room_quicksand\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Corridor-3x4-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"3x4_corridor\",\n",
        "    },\n",
        ")\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Full-4x5-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"4x5_full\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/TwoRoom-Distract-Middle-2x11-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:GridworldMiddleStart\",\n",
        "    max_episode_steps=200,\n",
        "    kwargs={\n",
        "        \"grid\": \"2x11_two_room_distract\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/Barrier-5x5-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=50,\n",
        "    kwargs={\n",
        "        \"grid\": \"5x5_barrier\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/RiverSwim-6-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:RiverSwim\",\n",
        "    max_episode_steps=200,\n",
        "    kwargs={\n",
        "        \"grid\": \"river_swim_6\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/CliffWalk-4x12-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=200,\n",
        "    kwargs={\n",
        "        \"grid\": \"4x12_cliffwalk\",\n",
        "    },\n",
        ")\n",
        "\n",
        "register(\n",
        "    id=\"Gym-Gridworlds/DangerMaze-6x6-v0\",\n",
        "    entry_point=\"gym_gridworlds.gridworld:Gridworld\",\n",
        "    max_episode_steps=200,\n",
        "    kwargs={\n",
        "        \"grid\": \"6x6_danger_maze\",\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "JngHQiknE_hC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "ArzuUc8WFVOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "import gym\n",
        "import gymnasium"
      ],
      "metadata": {
        "id": "HaIz8uDLTyZY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS8cWkmWGi4K",
        "outputId": "b634c302-6596-4a61-f959-b96fb930de68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Functions"
      ],
      "metadata": {
        "id": "joqj9DFyFkcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rbf_features(\n",
        "    state,\n",
        "    centers,\n",
        "    sigmas: float,\n",
        "):\n",
        "    state = torch.tensor(state, device=device)\n",
        "    centers = torch.tensor(centers, device=device)\n",
        "    D = centers.shape[0]\n",
        "    N = state.shape[0]\n",
        "    new_state = state[:, None, :].repeat(1, D, 1)\n",
        "    new_center = centers.repeat(N, 1, 1)\n",
        "    return torch.exp(-torch.linalg.norm(new_state - new_center, 2, axis=2)**2 / sigmas**2 / 2)\n",
        "\n",
        "\n",
        "def tile_features(\n",
        "    state: np.array,  # (N, S)\n",
        "    centers: np.array,  # (D, S)\n",
        "    widths: float,\n",
        "    offsets: list = [0],  # list of tuples of length S\n",
        ") -> np.array:  # (N, D)\n",
        "\n",
        "    D = np.shape(centers)[0]\n",
        "    N = np.shape(state)[0]\n",
        "    new_state = np.repeat(state[:, None, :], D, axis=1)\n",
        "    output = np.zeros((N, D))\n",
        "    for offset in offsets:\n",
        "        shifted_center = centers + offset\n",
        "        new_center = np.repeat(shifted_center[None, :, :], N, axis=0)\n",
        "        output += np.array(np.linalg.norm(new_state - new_center, np.inf, axis=2) < widths, dtype=np.float32)\n",
        "\n",
        "    return output / len(offsets)\n",
        "\n",
        "\n",
        "def coarse_features(\n",
        "    state: np.array,  # (N, S)\n",
        "    centers: np.array,  # (D, S)\n",
        "    widths: float,\n",
        "    offsets: list = [0],  # list of tuples of length S\n",
        ") -> np.array:  # (N, D)\n",
        "\n",
        "    D = np.shape(centers)[0]\n",
        "    N = np.shape(state)[0]\n",
        "    new_state = np.repeat(state[:, None, :], D, axis=1)\n",
        "    output = np.zeros((N, D))\n",
        "    for offset in offsets:\n",
        "        shifted_center = centers + offset\n",
        "        new_center = np.repeat(shifted_center[None, :, :], N, axis=0)\n",
        "        output += np.array(np.linalg.norm(new_state - new_center, 2, axis=2) < widths, dtype=np.float32)\n",
        "\n",
        "    return output / len(offsets)\n",
        "\n",
        "def aggregation_features(state, centers):\n",
        "    state = torch.tensor(state, device=device)\n",
        "    centers = torch.tensor(centers, device=device)\n",
        "\n",
        "    distance = torch.sum((state[:, None, :] - centers[None, :, :])**2, dim=-1)\n",
        "    return (distance == distance.min(-1, keepdims=True).values) * 1.0  # make it float\n"
      ],
      "metadata": {
        "id": "MHAAP-0zM7YS"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = np.array([[1, 2]])\n",
        "c = np.array([[0, 0], [1, 1], [4, 4], [6, 6]])\n",
        "aggregation_features(s, c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGcb4NywalLn",
        "outputId": "54b36349-d518-466c-c26e-57cdc5c2fa1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0., 0.]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network"
      ],
      "metadata": {
        "id": "6LaO9SJLFo7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "3WZeWiE8IG57"
      },
      "outputs": [],
      "source": [
        "# Define the neural network model\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.seed = torch.manual_seed(seed)\n",
        "\n",
        "        self.feature_size = self.feature_extract_init(state_size, action_size)\n",
        "        self.fc1 = nn.Linear(self.feature_size, fc1_units)\n",
        "        self.init_weights(self.fc1)\n",
        "        self.fc2 = nn.Linear(fc1_units, action_size)\n",
        "        self.init_weights(self.fc2)\n",
        "\n",
        "    def init_weights(self, layer):\n",
        "        nn.init.xavier_normal(layer.weight)\n",
        "        self.to(device)\n",
        "\n",
        "    def feature_extract_init(self, state_size, action_size):\n",
        "        n_centers = [3, 3]\n",
        "        centers = np.array(\n",
        "          np.meshgrid(*[\n",
        "              np.linspace(env.observation_space.low[i], env.observation_space.high[i], n_centers[i])\n",
        "              for i in range(env.observation_space.shape[0])\n",
        "          ])\n",
        "        ).reshape(env.observation_space.shape[0], -1).T\n",
        "        centers = torch.tensor(centers).float().to(device)\n",
        "        #self.feature_name, self.feature_extract = \"Aggregate\", lambda state : aggregation_features(state.reshape(-1, state_size), centers)\n",
        "        self.feature_name, self.feature_extract = \"RBF\", lambda state : rbf_features(state.reshape(-1, state_size), centers, 0.2)\n",
        "        return self.feature_extract(env.reset()[0]).shape[1]\n",
        "\n",
        "    def forward(self, state):\n",
        "        #x = F.relu(self.fc1(state))\n",
        "        #x = F.relu(self.fc2(x))\n",
        "        #return self.fc3(x)\n",
        "        x = self.feature_extract(state)\n",
        "        return self.fc2(self.fc1(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReplayBuffer"
      ],
      "metadata": {
        "id": "xH3J2_azF2Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=buffer_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        e = self.experience(state, action, reward, next_state, done)\n",
        "        self.memory.append(e)\n",
        "\n",
        "    def sample(self):\n",
        "        experiences = random.sample(self.memory, k=self.batch_size)\n",
        "\n",
        "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        return (states, actions, rewards, next_states, dones)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "WUEjnATTF0PM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN"
      ],
      "metadata": {
        "id": "Wq2snh0iFuqi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "SMqPt_ruIG59"
      },
      "outputs": [],
      "source": [
        "# Define the DQN agent class\n",
        "class DQNAgent:\n",
        "    # Initialize the DQN agent\n",
        "    def __init__(self, state_size, action_size, seed, lr):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.seed = random.seed(seed)\n",
        "\n",
        "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
        "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr)\n",
        "\n",
        "        self.memory = ReplayBuffer(action_size, buffer_size=int(1e5), batch_size=64, seed=seed)\n",
        "        self.t_step = 0\n",
        "\n",
        "    def step(self, state, action, reward, next_state, done):\n",
        "        self.memory.add(state, action, reward, next_state, done)\n",
        "\n",
        "        self.t_step = (self.t_step + 1) % 4\n",
        "        if self.t_step == 0:\n",
        "            if len(self.memory) > 64:\n",
        "                experiences = self.memory.sample()\n",
        "                self.learn(experiences, gamma=0.99)\n",
        "\n",
        "    # Choose an action based on the current state\n",
        "    def act(self, state, eps=0.):\n",
        "        state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "        self.qnetwork_local.eval()\n",
        "        with torch.no_grad():\n",
        "            action_values = self.qnetwork_local(state_tensor)\n",
        "        self.qnetwork_local.train()\n",
        "\n",
        "        if np.random.random() > eps:\n",
        "            return action_values.argmax(dim=1).item()\n",
        "        else:\n",
        "            return np.random.randint(self.action_size)\n",
        "\n",
        "    # Learn from batch of experiences\n",
        "    def learn(self, experiences, gamma):\n",
        "        states, actions, rewards, next_states, dones = zip(*experiences)\n",
        "        states = torch.from_numpy(np.vstack(states)).float().to(device)\n",
        "        actions = torch.from_numpy(np.vstack(actions)).long().to(device)\n",
        "        rewards = torch.from_numpy(np.vstack(rewards)).float().to(device)\n",
        "        next_states = torch.from_numpy(np.vstack(next_states)).float().to(device)\n",
        "        dones = torch.from_numpy(np.vstack(dones).astype(np.uint8)).float().to(device)\n",
        "\n",
        "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
        "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
        "\n",
        "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
        "\n",
        "        loss = F.mse_loss(Q_expected, Q_targets)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        self.soft_update(self.qnetwork_local, self.qnetwork_target, tau=1e-3)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def soft_update(self, local_model, target_model, tau):\n",
        "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
        "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "WxOD0rGTF_Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 1000\n",
        "max_steps_per_episode_train = 100\n",
        "max_steps_per_episode_eval = 10\n",
        "epsilon_start = 1.0\n",
        "epsilon_end = 0.02\n",
        "epsilon_decay_rate = 0.99\n",
        "gamma = 0.9\n",
        "lr = 1e-3\n",
        "buffer_size = 1000\n",
        "buffer = deque(maxlen=buffer_size)\n",
        "batch_size = 64\n",
        "update_frequency = 10\n",
        "episodes_eval = 10\n",
        "test_episodes = 100"
      ],
      "metadata": {
        "id": "ztLArg8OF-4o"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Environment"
      ],
      "metadata": {
        "id": "fek2zIOuF5Me"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSD8eiX5IG5-",
        "outputId": "cfbfbb2b-9738-47d5-bc7e-9bd72dc1daa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/spaces/box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
            "  gym.logger.warn(\n"
          ]
        }
      ],
      "source": [
        "env_id = \"Gym-Gridworlds/Penalty-3x3-v0\"\n",
        "env = gymnasium.make(env_id, coordinate_observation=True)\n",
        "env_eval = gymnasium.make(env_id, coordinate_observation=True, max_episode_steps=max_steps_per_episode_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN Agent"
      ],
      "metadata": {
        "id": "R_nWh5QTGSUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = env.observation_space.shape[0]\n",
        "output_dim = env.action_space.n\n",
        "new_agent = DQNAgent(input_dim, output_dim, seed=170715, lr = lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqDLGgWFGVTO",
        "outputId": "8c566568-741e-4cbb-f14c-f45e307cd98e"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-09a9753fb6cf>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  centers = torch.tensor(centers, device=device)\n",
            "<ipython-input-142-ee3692fa93d9>:14: FutureWarning: `nn.init.xavier_normal` is now deprecated in favor of `nn.init.xavier_normal_`.\n",
            "  nn.init.xavier_normal(layer.weight)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "VEyTwl3aGWTF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rpzjfY2IG5-",
        "outputId": "6bd8a360-75bd-486a-807e-d6beebd7c987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-09a9753fb6cf>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  state = torch.tensor(state, device=device)\n",
            "<ipython-input-130-09a9753fb6cf>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  centers = torch.tensor(centers, device=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 10: reward -704.0, loss 2171.42041015625, epsilon 0.9135172474836408\n",
            "Episode 20: reward -666.0, loss 26.158245086669922, epsilon 0.8261686238355866\n",
            "Episode 30: reward -323.0, loss 12.700183868408203, epsilon 0.7471720943315961\n",
            "Episode 40: reward -255.0, loss 7.8970160484313965, epsilon 0.6757290490602831\n",
            "Episode 50: reward -213.0, loss 4.5646467208862305, epsilon 0.611117239532865\n",
            "Episode 60: reward -263.0, loss 2.387547016143799, epsilon 0.5526834771623851\n",
            "Episode 70: reward -113.0, loss 1.0456233024597168, epsilon 0.4998370298991989\n",
            "Episode 80: reward -104.0, loss 0.7678964138031006, epsilon 0.45204365026647536\n",
            "Episode 90: reward -43.0, loss 0.31764477491378784, epsilon 0.40882017442254925\n",
            "Episode 100: reward -133.0, loss 0.452567994594574, epsilon 0.36972963764972644\n",
            "Episode 110: reward -81.0, loss 0.25012537837028503, epsilon 0.334376856889913\n",
            "Episode 120: reward -40.0, loss 0.12509770691394806, epsilon 0.30240443566902153\n",
            "Episode 130: reward -70.0, loss 0.1015515923500061, epsilon 0.2734891510222162\n",
            "Episode 140: reward -11.0, loss 0.059207476675510406, epsilon 0.24733868589386818\n",
            "Episode 150: reward -21.0, loss 0.09943193942308426, epsilon 0.2236886739786474\n",
            "Episode 160: reward -30.0, loss 0.033704645931720734, epsilon 0.2023000271287771\n",
            "Episode 170: reward -40.0, loss 0.07788505405187607, epsilon 0.18295651830906084\n",
            "Episode 180: reward 0.0, loss 0.06596212089061737, epsilon 0.16546259566473476\n",
            "Episode 190: reward -10.0, loss 0.14758984744548798, epsilon 0.14964140560361563\n",
            "Episode 200: reward -20.0, loss 0.14264820516109467, epsilon 0.13533300490703204\n",
            "Episode 210: reward 0.0, loss 0.13867314159870148, epsilon 0.12239274379499834\n",
            "Episode 220: reward -50.0, loss 0.0465790331363678, epsilon 0.11068980359934157\n",
            "Episode 230: reward 10.0, loss 0.06773719191551208, epsilon 0.10010587426148955\n",
            "Episode 240: reward -10.0, loss 0.00035134173231199384, epsilon 0.0905339582851764\n",
            "Episode 250: reward 0.0, loss 2.047415910055861e-05, epsilon 0.08187728905270836\n",
            "Episode 260: reward -10.0, loss 4.781524239660939e-06, epsilon 0.07404835256958406\n",
            "Episode 270: reward 10.0, loss 5.117129148857202e-06, epsilon 0.06696800274786396\n",
            "Episode 280: reward 10.0, loss 5.599657015409321e-06, epsilon 0.06056466128430853\n",
            "Episode 290: reward 10.0, loss 4.1985895222751424e-05, epsilon 0.05477359404450834\n",
            "Episode 300: reward 10.0, loss 3.997452222392894e-05, epsilon 0.04953625663766235\n",
            "Episode 310: reward 10.0, loss 5.409249752119649e-06, epsilon 0.04479970256613774\n",
            "Episode 320: reward 10.0, loss 3.947088771383278e-06, epsilon 0.0405160479665409\n",
            "Episode 330: reward 0.0, loss 9.090148523682728e-06, epsilon 0.03664198753113651\n",
            "Episode 340: reward 10.0, loss 2.447208089506603e-06, epsilon 0.03313835671585598\n",
            "Episode 350: reward 10.0, loss 2.90419870907499e-06, epsilon 0.02996973580906778\n",
            "Episode 360: reward 10.0, loss 1.6372074469472864e-06, epsilon 0.02710409185847039\n",
            "Episode 370: reward 0.0, loss 2.11524820770137e-06, epsilon 0.02451245483619269\n",
            "Episode 380: reward 10.0, loss 1.8606745015858905e-06, epsilon 0.022168624768315548\n",
            "Episode 390: reward 10.0, loss 1.4012809970154194e-06, epsilon 0.02004890686806079\n",
            "Episode 400: reward 10.0, loss 1.5507768011957523e-06, epsilon 0.02\n",
            "Episode 410: reward 10.0, loss 1.037844981510716e-06, epsilon 0.02\n",
            "Episode 420: reward 10.0, loss 1.0200425322182127e-06, epsilon 0.02\n",
            "Episode 430: reward 10.0, loss 2.5270765036111698e-06, epsilon 0.02\n",
            "Episode 440: reward 10.0, loss 1.910294713525218e-06, epsilon 0.02\n",
            "Episode 450: reward 10.0, loss 2.5272411221521907e-06, epsilon 0.02\n",
            "Episode 460: reward 10.0, loss 1.0031295687440434e-06, epsilon 0.02\n",
            "Episode 470: reward 0.0, loss 3.70651787306997e-06, epsilon 0.02\n",
            "Episode 480: reward -10.0, loss 2.013085577345919e-06, epsilon 0.02\n",
            "Episode 490: reward 10.0, loss 6.813654636061983e-07, epsilon 0.02\n",
            "Episode 500: reward 10.0, loss 6.632831355091184e-05, epsilon 0.02\n",
            "Episode 510: reward 10.0, loss 4.168103259871714e-05, epsilon 0.02\n",
            "Episode 520: reward 10.0, loss 2.9199996788520366e-05, epsilon 0.02\n",
            "Episode 530: reward 10.0, loss 1.2630456694751047e-05, epsilon 0.02\n",
            "Episode 540: reward 10.0, loss 1.1165541309310356e-06, epsilon 0.02\n",
            "Episode 550: reward 0.0, loss 7.795403007548884e-07, epsilon 0.02\n",
            "Episode 560: reward 10.0, loss 1.4896742868586443e-05, epsilon 0.02\n",
            "Episode 570: reward 10.0, loss 3.0331730158650316e-05, epsilon 0.02\n",
            "Episode 580: reward 10.0, loss 0.0003016431292053312, epsilon 0.02\n",
            "Episode 590: reward 10.0, loss 0.0010649515315890312, epsilon 0.02\n",
            "Episode 600: reward 10.0, loss 0.0005316883907653391, epsilon 0.02\n",
            "Episode 610: reward 10.0, loss 3.455626574577764e-05, epsilon 0.02\n",
            "Episode 620: reward 10.0, loss 1.3218224921729416e-05, epsilon 0.02\n",
            "Episode 630: reward 10.0, loss 4.071867078891955e-05, epsilon 0.02\n",
            "Episode 640: reward 10.0, loss 7.155476487241685e-05, epsilon 0.02\n",
            "Episode 650: reward 10.0, loss 4.045951573061757e-05, epsilon 0.02\n",
            "Episode 660: reward 10.0, loss 0.00014543764700647444, epsilon 0.02\n",
            "Episode 670: reward 10.0, loss 3.2290812669089064e-05, epsilon 0.02\n",
            "Episode 680: reward 10.0, loss 4.555565828923136e-05, epsilon 0.02\n",
            "Episode 690: reward 10.0, loss 4.0420691220788285e-05, epsilon 0.02\n",
            "Episode 700: reward 10.0, loss 0.0007159104570746422, epsilon 0.02\n",
            "Episode 710: reward 10.0, loss 0.0020210088696330786, epsilon 0.02\n",
            "Episode 720: reward -10.0, loss 0.0003201144572813064, epsilon 0.02\n",
            "Episode 730: reward 10.0, loss 0.0002414591290289536, epsilon 0.02\n",
            "Episode 740: reward 10.0, loss 0.00010503169323783368, epsilon 0.02\n",
            "Episode 750: reward 10.0, loss 0.00018777954392135143, epsilon 0.02\n",
            "Episode 760: reward 10.0, loss 0.0005608667270280421, epsilon 0.02\n",
            "Episode 770: reward 10.0, loss 0.000584650260861963, epsilon 0.02\n",
            "Episode 780: reward 0.0, loss 0.0018634205916896462, epsilon 0.02\n",
            "Episode 790: reward 10.0, loss 0.002522001974284649, epsilon 0.02\n",
            "Episode 800: reward 10.0, loss 0.001322777708992362, epsilon 0.02\n",
            "Episode 810: reward 10.0, loss 0.00041052146116271615, epsilon 0.02\n",
            "Episode 820: reward 10.0, loss 0.00020545904408209026, epsilon 0.02\n",
            "Episode 830: reward 10.0, loss 0.0002323356457054615, epsilon 0.02\n",
            "Episode 840: reward 10.0, loss 0.0009984191274270415, epsilon 0.02\n",
            "Episode 850: reward 0.0, loss 0.0025380298029631376, epsilon 0.02\n",
            "Episode 860: reward 10.0, loss 0.002032067161053419, epsilon 0.02\n",
            "Episode 870: reward 10.0, loss 0.000458190799690783, epsilon 0.02\n",
            "Episode 880: reward 10.0, loss 0.0002831103920470923, epsilon 0.02\n",
            "Episode 890: reward 10.0, loss 0.00015264310059137642, epsilon 0.02\n",
            "Episode 900: reward 0.0, loss 0.00019100456847809255, epsilon 0.02\n",
            "Episode 910: reward 10.0, loss 0.00018177571473643184, epsilon 0.02\n",
            "Episode 920: reward 10.0, loss 0.0001595138746779412, epsilon 0.02\n",
            "Episode 930: reward 10.0, loss 0.0005125333555042744, epsilon 0.02\n",
            "Episode 940: reward 10.0, loss 0.0008961402927525342, epsilon 0.02\n",
            "Episode 950: reward 10.0, loss 0.00015252943558152765, epsilon 0.02\n",
            "Episode 960: reward -10.0, loss 0.006329593248665333, epsilon 0.02\n",
            "Episode 970: reward 10.0, loss 0.007833045907318592, epsilon 0.02\n",
            "Episode 980: reward 10.0, loss 0.0076137506403028965, epsilon 0.02\n",
            "Episode 990: reward 10.0, loss 0.0004463595396373421, epsilon 0.02\n",
            "Episode 1000: reward 0.0, loss 0.0016627972945570946, epsilon 0.02\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "ep_mean_reward = 0\n",
        "ep_mean_loss = 0\n",
        "losses = []\n",
        "rewards = []\n",
        "for episode in range(num_episodes):\n",
        "    # Reset the environment\n",
        "    state, _ = env.reset()\n",
        "    epsilon = max(epsilon_end, epsilon_start * (epsilon_decay_rate ** episode))\n",
        "\n",
        "    ep_reward = 0\n",
        "    ep_loss = 0\n",
        "    # Run one episode\n",
        "    for step in range(max_steps_per_episode_train):\n",
        "        # Choose and perform an action\n",
        "        action = new_agent.act(state, epsilon)\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        #print(reward)\n",
        "        buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "        #print(len(buffer), batch_size)\n",
        "        if len(buffer) >= batch_size:\n",
        "            batch = random.sample(buffer, batch_size)\n",
        "            # Update the agent's knowledge\n",
        "            loss = new_agent.learn(batch, gamma)\n",
        "            ep_loss += loss\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "        ep_reward += reward\n",
        "        # Check if the episode has ended\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    losses.append(ep_loss)\n",
        "    ep_mean_reward += ep_reward\n",
        "    ep_mean_loss += ep_loss\n",
        "    if (episode + 1) % update_frequency == 0:\n",
        "        print(f\"Episode {episode + 1}: reward {ep_mean_reward}, loss {ep_mean_loss}, epsilon {epsilon}\")\n",
        "        ep_mean_reward = 0\n",
        "        ep_mean_loss = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "qSYXkfXHGYpu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "DT3DPKDFIG5_",
        "outputId": "3cc5a2a4-5068-4e67-a57c-47561cf95b46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-130-09a9753fb6cf>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  state = torch.tensor(state, device=device)\n",
            "<ipython-input-130-09a9753fb6cf>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  centers = torch.tensor(centers, device=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "-----\n",
            "[0. 0.] 1\n",
            "[1. 0.] 1\n",
            "[2. 0.] 2\n",
            "[2. 1.] 2\n",
            "[2. 2.] 3\n",
            "[1. 2.] 3\n",
            "[0. 2.] 4\n",
            "Average reward over 100 test episodes: 1.00\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the agent's performance\n",
        "episode_rewards = []\n",
        "\n",
        "for episode in range(test_episodes):\n",
        "    state, _ = env.reset()\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    print(\"-----\")\n",
        "    while not done:\n",
        "        action = new_agent.act(state, eps=0.)\n",
        "        print(state, action)\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        episode_reward += reward\n",
        "        state = next_state\n",
        "\n",
        "    episode_rewards.append(episode_reward)\n",
        "\n",
        "average_reward = sum(episode_rewards) / test_episodes\n",
        "print(f\"Average reward over {test_episodes} test episodes: {average_reward:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "ptjV-i4LGaj4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "id": "l-tXrSnDIG5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "d841255f-0438-418b-9047-ed1de7b3c64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a98c5893c10>]"
            ]
          },
          "metadata": {},
          "execution_count": 199
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualize the agent's performance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "losses_cpu = [loss.cpu().detach().numpy() for loss in losses][:100]\n",
        "plt.plot(list(range(len(losses_cpu))), losses_cpu)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "W3Gq3o_bGy10",
        "xH3J2_azF2Xh"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}